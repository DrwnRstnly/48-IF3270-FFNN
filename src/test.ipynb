{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from classes.NeuralNetwork import NeuralNetwork\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 70000 entries, 0 to 69999\n",
      "Columns: 785 entries, pixel1 to class\n",
      "dtypes: category(1), int64(784)\n",
      "memory usage: 418.8 MB\n"
     ]
    }
   ],
   "source": [
    "mnist = fetch_openml('mnist_784', version=1)\n",
    "mnist.frame.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = mnist.data.astype(np.float32)\n",
    "y = mnist.target.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, X_test, y, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train_raw, y_val_raw = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "y_train = encoder.fit_transform(y_train_raw.values.reshape(-1, 1))\n",
    "y_val = encoder.transform(y_val_raw.values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9083928571428571\n"
     ]
    }
   ],
   "source": [
    "nn_model = NeuralNetwork(\n",
    "    input_size=784,\n",
    "    layers_config=[(64, 'linear'), (10, 'softmax')],\n",
    "    weight_init='random_uniform',\n",
    "    weight_init_params={'low': -0.01, 'high': 0.01, 'seed': 42}\n",
    ")\n",
    "history = nn_model.train(X_train, y_train, X_val, y_val, batch_size=128, learning_rate=0.01, max_epoch=100, verbose=0)\n",
    "y_preds = nn_model.predict(X_val)\n",
    "y_preds = np.argmax(y_preds,axis=1)\n",
    "print(f'Accuracy: {accuracy_score(y_val_raw, y_preds)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_loss': [np.float64(0.0899389094422457),\n",
       "  np.float64(0.08988061108443077),\n",
       "  np.float64(0.0898025100808638),\n",
       "  np.float64(0.08968983602885089),\n",
       "  np.float64(0.08951899945055179),\n",
       "  np.float64(0.08924990922302241),\n",
       "  np.float64(0.0888079683648003),\n",
       "  np.float64(0.088032550594),\n",
       "  np.float64(0.08651955243763682),\n",
       "  np.float64(0.08365170312929766),\n",
       "  np.float64(0.07995110181362515),\n",
       "  np.float64(0.07583545550033222),\n",
       "  np.float64(0.07173152506238463),\n",
       "  np.float64(0.06711854658449383),\n",
       "  np.float64(0.061585211833680806),\n",
       "  np.float64(0.05574281923774128),\n",
       "  np.float64(0.050660565587627465),\n",
       "  np.float64(0.04637868952724709),\n",
       "  np.float64(0.042611438171127516),\n",
       "  np.float64(0.039064657944854315),\n",
       "  np.float64(0.03582767478811457),\n",
       "  np.float64(0.03301312345924161),\n",
       "  np.float64(0.030619584847734214),\n",
       "  np.float64(0.028613113904673207),\n",
       "  np.float64(0.026935111028663323),\n",
       "  np.float64(0.02552183821532564),\n",
       "  np.float64(0.02433158075069945),\n",
       "  np.float64(0.02331980977621855),\n",
       "  np.float64(0.022454767212388524),\n",
       "  np.float64(0.021702784950828054),\n",
       "  np.float64(0.021048530064967194),\n",
       "  np.float64(0.020471492210458683),\n",
       "  np.float64(0.01995890187289029),\n",
       "  np.float64(0.019505510092474636),\n",
       "  np.float64(0.019094121018884722),\n",
       "  np.float64(0.018723751960159365),\n",
       "  np.float64(0.01838699298562645),\n",
       "  np.float64(0.01807998522242894),\n",
       "  np.float64(0.017801566750262284),\n",
       "  np.float64(0.01754127120191905),\n",
       "  np.float64(0.017303458819215634),\n",
       "  np.float64(0.01708331861089585),\n",
       "  np.float64(0.01687312295620572),\n",
       "  np.float64(0.016682189520528398),\n",
       "  np.float64(0.016501897057180706),\n",
       "  np.float64(0.016334690351899803),\n",
       "  np.float64(0.016175246617210974),\n",
       "  np.float64(0.016025880414413076),\n",
       "  np.float64(0.015885360340502627),\n",
       "  np.float64(0.015750245453105164),\n",
       "  np.float64(0.015623327665898442),\n",
       "  np.float64(0.01550361545888867),\n",
       "  np.float64(0.01538911779019853),\n",
       "  np.float64(0.015279089800553328),\n",
       "  np.float64(0.015172977768495265),\n",
       "  np.float64(0.015073416737248395),\n",
       "  np.float64(0.014977232694682652),\n",
       "  np.float64(0.014884171809288218),\n",
       "  np.float64(0.0147976080191635),\n",
       "  np.float64(0.014712040935414429),\n",
       "  np.float64(0.014629511617405966),\n",
       "  np.float64(0.01455087233418222),\n",
       "  np.float64(0.014474576510862223),\n",
       "  np.float64(0.01440217825216987),\n",
       "  np.float64(0.014331433535087852),\n",
       "  np.float64(0.014263162459418804),\n",
       "  np.float64(0.014199303419785125),\n",
       "  np.float64(0.014134003971165803),\n",
       "  np.float64(0.014074962012240465),\n",
       "  np.float64(0.014014061421634291),\n",
       "  np.float64(0.013961595519819653),\n",
       "  np.float64(0.013902736133993296),\n",
       "  np.float64(0.013852111669521033),\n",
       "  np.float64(0.013796264960978834),\n",
       "  np.float64(0.01374459129667242),\n",
       "  np.float64(0.013695471196015982),\n",
       "  np.float64(0.013643670686554676),\n",
       "  np.float64(0.013597910364089399),\n",
       "  np.float64(0.013552774278045127),\n",
       "  np.float64(0.013507856461152263),\n",
       "  np.float64(0.01346414428718595),\n",
       "  np.float64(0.013422229221238315),\n",
       "  np.float64(0.013379412978983016),\n",
       "  np.float64(0.01334024368663416),\n",
       "  np.float64(0.01330318031862664),\n",
       "  np.float64(0.013262765813001504),\n",
       "  np.float64(0.013225516989897339),\n",
       "  np.float64(0.013189300133060928),\n",
       "  np.float64(0.013154957107364376),\n",
       "  np.float64(0.013118470462340825),\n",
       "  np.float64(0.013083486935931091),\n",
       "  np.float64(0.013050616752759453),\n",
       "  np.float64(0.013018795024627723),\n",
       "  np.float64(0.012985563890686648),\n",
       "  np.float64(0.012953700405175836),\n",
       "  np.float64(0.012924434001583442),\n",
       "  np.float64(0.012898318427121355),\n",
       "  np.float64(0.012865831564855676),\n",
       "  np.float64(0.012836222139383034),\n",
       "  np.float64(0.012809053819237677)],\n",
       " 'val_loss': [np.float64(0.08993742771869728),\n",
       "  np.float64(0.08987931573651661),\n",
       "  np.float64(0.08980164183949298),\n",
       "  np.float64(0.0896898103250581),\n",
       "  np.float64(0.08952057967649432),\n",
       "  np.float64(0.08925459576406355),\n",
       "  np.float64(0.08881899348608105),\n",
       "  np.float64(0.08805806080463803),\n",
       "  np.float64(0.08658323871692383),\n",
       "  np.float64(0.08378603153457391),\n",
       "  np.float64(0.08008392645285826),\n",
       "  np.float64(0.07589770141896393),\n",
       "  np.float64(0.07173686324243446),\n",
       "  np.float64(0.06707764550645554),\n",
       "  np.float64(0.0614875086703089),\n",
       "  np.float64(0.05562185020204342),\n",
       "  np.float64(0.050551685049800656),\n",
       "  np.float64(0.04627469792983582),\n",
       "  np.float64(0.04249448447376486),\n",
       "  np.float64(0.038913629031147284),\n",
       "  np.float64(0.035650645593916654),\n",
       "  np.float64(0.03282229600572265),\n",
       "  np.float64(0.030417708341980466),\n",
       "  np.float64(0.028413913949697046),\n",
       "  np.float64(0.026742063051172882),\n",
       "  np.float64(0.025332897110706843),\n",
       "  np.float64(0.024148311475258775),\n",
       "  np.float64(0.023142863452891002),\n",
       "  np.float64(0.0222739274336922),\n",
       "  np.float64(0.021525249825918715),\n",
       "  np.float64(0.020878036922226905),\n",
       "  np.float64(0.02030056124059955),\n",
       "  np.float64(0.01978399717593767),\n",
       "  np.float64(0.019326667054148372),\n",
       "  np.float64(0.018915617476056995),\n",
       "  np.float64(0.01854682137375101),\n",
       "  np.float64(0.01820475829888449),\n",
       "  np.float64(0.017896889254163308),\n",
       "  np.float64(0.01761511788564397),\n",
       "  np.float64(0.017357601293486),\n",
       "  np.float64(0.01712603558019479),\n",
       "  np.float64(0.01690331631224041),\n",
       "  np.float64(0.01669417241831135),\n",
       "  np.float64(0.016504198486246485),\n",
       "  np.float64(0.01632548997038309),\n",
       "  np.float64(0.01615924048379686),\n",
       "  np.float64(0.01600472703603113),\n",
       "  np.float64(0.015854379426507047),\n",
       "  np.float64(0.015713628899050213),\n",
       "  np.float64(0.015584121926395028),\n",
       "  np.float64(0.015463012175128783),\n",
       "  np.float64(0.01534007805682694),\n",
       "  np.float64(0.015236230408674277),\n",
       "  np.float64(0.015130174106031674),\n",
       "  np.float64(0.015028677439171497),\n",
       "  np.float64(0.01493059669357387),\n",
       "  np.float64(0.01483655886983235),\n",
       "  np.float64(0.01475329345099467),\n",
       "  np.float64(0.014663894267398642),\n",
       "  np.float64(0.014592772385569691),\n",
       "  np.float64(0.014512189427509882),\n",
       "  np.float64(0.01443863236184752),\n",
       "  np.float64(0.014366225378893907),\n",
       "  np.float64(0.014297038464569605),\n",
       "  np.float64(0.01423461797924795),\n",
       "  np.float64(0.014170831541054767),\n",
       "  np.float64(0.014115121868462727),\n",
       "  np.float64(0.01405375586122131),\n",
       "  np.float64(0.01399112831815803),\n",
       "  np.float64(0.013940455113378056),\n",
       "  np.float64(0.013898798679658474),\n",
       "  np.float64(0.013833129761400413),\n",
       "  np.float64(0.013804965760130608),\n",
       "  np.float64(0.013747520891319866),\n",
       "  np.float64(0.01370316098894882),\n",
       "  np.float64(0.013660616385454944),\n",
       "  np.float64(0.013609047448822789),\n",
       "  np.float64(0.013567211374257163),\n",
       "  np.float64(0.013537200318716707),\n",
       "  np.float64(0.013496852991796824),\n",
       "  np.float64(0.013452391946791271),\n",
       "  np.float64(0.01341086717740516),\n",
       "  np.float64(0.013376592670115218),\n",
       "  np.float64(0.013348288781497915),\n",
       "  np.float64(0.013308804964795914),\n",
       "  np.float64(0.013275915358883852),\n",
       "  np.float64(0.013246258386471425),\n",
       "  np.float64(0.01321685468114854),\n",
       "  np.float64(0.013188075972375814),\n",
       "  np.float64(0.013156345317223404),\n",
       "  np.float64(0.013124588195439341),\n",
       "  np.float64(0.013098439314012467),\n",
       "  np.float64(0.01307039798970834),\n",
       "  np.float64(0.013043809705817163),\n",
       "  np.float64(0.013016153549939754),\n",
       "  np.float64(0.012991981836596353),\n",
       "  np.float64(0.012974104243395148),\n",
       "  np.float64(0.012947947365098543),\n",
       "  np.float64(0.012914252468114411),\n",
       "  np.float64(0.012897996063219487)]}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn MLPClassifier Accuracy: 0.9171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "sk_model = MLPClassifier(\n",
    "    hidden_layer_sizes=(64,),\n",
    "    activation='identity', \n",
    "    solver='sgd',\n",
    "    alpha=0.0,\n",
    "    batch_size=128,\n",
    "    learning_rate_init=0.01,\n",
    "    max_iter=100,\n",
    "    random_state=42\n",
    ")\n",
    "sk_model.fit(X_train, y_train_raw)\n",
    "sk_preds = sk_model.predict(X_val)\n",
    "sk_acc = accuracy_score(y_val_raw, sk_preds)\n",
    "print(f\"sklearn MLPClassifier Accuracy: {sk_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5657142857142857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/derwinrustanly/Code/Python/48-IF3270-FFNN/src/classes/Layer.py:30: RuntimeWarning: overflow encountered in exp\n",
      "  exps = np.exp(z)\n",
      "/Users/derwinrustanly/Code/Python/48-IF3270-FFNN/src/classes/Layer.py:31: RuntimeWarning: invalid value encountered in divide\n",
      "  return exps / np.sum(exps, axis=1, keepdims=True)\n"
     ]
    }
   ],
   "source": [
    "y_preds = nn_model.predict(X_test)\n",
    "y_preds = np.argmax(y_preds,axis=1)\n",
    "print(f'Accuracy: {accuracy_score(y_test, y_preds)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn MLPClassifier Accuracy: 0.8484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.13/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but MLPClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "sk_preds = sk_model.predict(X_test)\n",
    "sk_acc = accuracy_score(y_test, sk_preds)\n",
    "print(f\"sklearn MLPClassifier Accuracy: {sk_acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
